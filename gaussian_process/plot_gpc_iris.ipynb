{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b68399",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=====================================================\n",
    "Gaussian process classification (GPC) on iris dataset\n",
    "=====================================================\n",
    "\n",
    "This example illustrates the predicted probability of GPC for an isotropic\n",
    "and anisotropic RBF kernel on a two-dimensional version for the iris-dataset.\n",
    "The anisotropic RBF kernel obtains slightly higher log-marginal-likelihood by\n",
    "assigning different length-scales to the two feature dimensions.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Authors: The scikit-learn developers\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = np.array(iris.target, dtype=int)\n",
    "\n",
    "h = 0.02  # step size in the mesh\n",
    "\n",
    "kernel = 1.0 * RBF([1.0])\n",
    "gpc_rbf_isotropic = GaussianProcessClassifier(kernel=kernel).fit(X, y)\n",
    "kernel = 1.0 * RBF([1.0, 1.0])\n",
    "gpc_rbf_anisotropic = GaussianProcessClassifier(kernel=kernel).fit(X, y)\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "titles = [\"Isotropic RBF\", \"Anisotropic RBF\"]\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, clf in enumerate((gpc_rbf_isotropic, gpc_rbf_anisotropic)):\n",
    "    # Plot the predicted probabilities. For that, we will assign a color to\n",
    "    # each point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "\n",
    "    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape((xx.shape[0], xx.shape[1], 3))\n",
    "    plt.imshow(Z, extent=(x_min, x_max, y_min, y_max), origin=\"lower\")\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=np.array([\"r\", \"g\", \"b\"])[y], edgecolors=(0, 0, 0))\n",
    "    plt.xlabel(\"Sepal length\")\n",
    "    plt.ylabel(\"Sepal width\")\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(\n",
    "        \"%s, LML: %.3f\" % (titles[i], clf.log_marginal_likelihood(clf.kernel_.theta))\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
