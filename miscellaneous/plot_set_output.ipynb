{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e248ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================\n",
    "Introducing the `set_output` API\n",
    "================================\n",
    "\n",
    ".. currentmodule:: sklearn\n",
    "\n",
    "This example will demonstrate the `set_output` API to configure transformers to\n",
    "output pandas DataFrames. `set_output` can be configured per estimator by calling\n",
    "the `set_output` method or globally by setting `set_config(transform_output=\"pandas\")`.\n",
    "For details, see\n",
    "`SLEP018 <https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep018/proposal.html>`__.\n",
    "\"\"\"  # noqa\n",
    "\n",
    "# %%\n",
    "# First, we load the iris dataset as a DataFrame to demonstrate the `set_output` API.\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_iris(as_frame=True, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "X_train.head()\n",
    "\n",
    "# %%\n",
    "# To configure an estimator such as :class:`preprocessing.StandardScaler` to return\n",
    "# DataFrames, call `set_output`. This feature requires pandas to be installed.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled.head()\n",
    "\n",
    "# %%\n",
    "# `set_output` can be called after `fit` to configure `transform` after the fact.\n",
    "scaler2 = StandardScaler()\n",
    "\n",
    "scaler2.fit(X_train)\n",
    "X_test_np = scaler2.transform(X_test)\n",
    "print(f\"Default output type: {type(X_test_np).__name__}\")\n",
    "\n",
    "scaler2.set_output(transform=\"pandas\")\n",
    "X_test_df = scaler2.transform(X_test)\n",
    "print(f\"Configured pandas output type: {type(X_test_df).__name__}\")\n",
    "\n",
    "# %%\n",
    "# In a :class:`pipeline.Pipeline`, `set_output` configures all steps to output\n",
    "# DataFrames.\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "clf = make_pipeline(\n",
    "    StandardScaler(), SelectPercentile(percentile=75), LogisticRegression()\n",
    ")\n",
    "clf.set_output(transform=\"pandas\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# %%\n",
    "# Each transformer in the pipeline is configured to return DataFrames. This\n",
    "# means that the final logistic regression step contains the feature names of the input.\n",
    "clf[-1].feature_names_in_\n",
    "\n",
    "# %%\n",
    "# .. note:: If one uses the method `set_params`, the transformer will be\n",
    "#    replaced by a new one with the default output format.\n",
    "clf.set_params(standardscaler=StandardScaler())\n",
    "clf.fit(X_train, y_train)\n",
    "clf[-1].feature_names_in_\n",
    "\n",
    "# %%\n",
    "# To keep the intended behavior, use `set_output` on the new transformer\n",
    "# beforehand\n",
    "scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "clf.set_params(standardscaler=scaler)\n",
    "clf.fit(X_train, y_train)\n",
    "clf[-1].feature_names_in_\n",
    "\n",
    "# %%\n",
    "# Next we load the titanic dataset to demonstrate `set_output` with\n",
    "# :class:`compose.ColumnTransformer` and heterogeneous data.\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "# %%\n",
    "# The `set_output` API can be configured globally by using :func:`set_config` and\n",
    "# setting `transform_output` to `\"pandas\"`.\n",
    "from sklearn import set_config\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "num_pipe = make_pipeline(SimpleImputer(), StandardScaler())\n",
    "num_cols = [\"age\", \"fare\"]\n",
    "ct = ColumnTransformer(\n",
    "    (\n",
    "        (\"numerical\", num_pipe, num_cols),\n",
    "        (\n",
    "            \"categorical\",\n",
    "            OneHotEncoder(\n",
    "                sparse_output=False, drop=\"if_binary\", handle_unknown=\"ignore\"\n",
    "            ),\n",
    "            [\"embarked\", \"sex\", \"pclass\"],\n",
    "        ),\n",
    "    ),\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "clf = make_pipeline(ct, SelectPercentile(percentile=50), LogisticRegression())\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "# %%\n",
    "# With the global configuration, all transformers output DataFrames. This allows us to\n",
    "# easily plot the logistic regression coefficients with the corresponding feature names.\n",
    "import pandas as pd\n",
    "\n",
    "log_reg = clf[-1]\n",
    "coef = pd.Series(log_reg.coef_.ravel(), index=log_reg.feature_names_in_)\n",
    "_ = coef.sort_values().plot.barh()\n",
    "\n",
    "# %%\n",
    "# In order to demonstrate the :func:`config_context` functionality below, let\n",
    "# us first reset `transform_output` to its default value.\n",
    "set_config(transform_output=\"default\")\n",
    "\n",
    "# %%\n",
    "# When configuring the output type with :func:`config_context` the\n",
    "# configuration at the time when `transform` or `fit_transform` are\n",
    "# called is what counts. Setting these only when you construct or fit\n",
    "# the transformer has no effect.\n",
    "from sklearn import config_context\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[num_cols])\n",
    "\n",
    "# %%\n",
    "with config_context(transform_output=\"pandas\"):\n",
    "    # the output of transform will be a Pandas DataFrame\n",
    "    X_test_scaled = scaler.transform(X_test[num_cols])\n",
    "X_test_scaled.head()\n",
    "\n",
    "# %%\n",
    "# outside of the context manager, the output will be a NumPy array\n",
    "X_test_scaled = scaler.transform(X_test[num_cols])\n",
    "X_test_scaled[:5]\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
