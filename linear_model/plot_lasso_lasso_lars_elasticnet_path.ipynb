{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a0a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "========================================\n",
    "Lasso, Lasso-LARS, and Elastic Net paths\n",
    "========================================\n",
    "\n",
    "This example shows how to compute the \"paths\" of coefficients along the Lasso,\n",
    "Lasso-LARS, and Elastic Net regularization paths. In other words, it shows the\n",
    "relationship between the regularization parameter (alpha) and the coefficients.\n",
    "\n",
    "Lasso and Lasso-LARS impose a sparsity constraint on the coefficients,\n",
    "encouraging some of them to be zero. Elastic Net is a generalization of\n",
    "Lasso that adds an L2 penalty term to the L1 penalty term. This allows for\n",
    "some coefficients to be non-zero while still encouraging sparsity.\n",
    "\n",
    "Lasso and Elastic Net use a coordinate descent method to compute the paths, while\n",
    "Lasso-LARS uses the LARS algorithm to compute the paths.\n",
    "\n",
    "The paths are computed using :func:`~sklearn.linear_model.lasso_path`,\n",
    ":func:`~sklearn.linear_model.lars_path`, and :func:`~sklearn.linear_model.enet_path`.\n",
    "\n",
    "The results show different comparison plots:\n",
    "\n",
    "- Compare Lasso and Lasso-LARS\n",
    "- Compare Lasso and Elastic Net\n",
    "- Compare Lasso with positive Lasso\n",
    "- Compare LARS and Positive LARS\n",
    "- Compare Elastic Net and positive Elastic Net\n",
    "\n",
    "Each plot shows how the model coefficients vary as the regularization strength changes,\n",
    "offering insight into the behavior of these models\n",
    "under different constraints.\n",
    "\"\"\"\n",
    "\n",
    "# Authors: The scikit-learn developers\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import enet_path, lars_path, lasso_path\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X /= X.std(axis=0)  # Standardize data (easier to set the l1_ratio parameter)\n",
    "\n",
    "# Compute paths\n",
    "\n",
    "eps = 5e-3  # the smaller it is the longer is the path\n",
    "\n",
    "print(\"Computing regularization path using the lasso...\")\n",
    "alphas_lasso, coefs_lasso, _ = lasso_path(X, y, eps=eps)\n",
    "\n",
    "print(\"Computing regularization path using the positive lasso...\")\n",
    "alphas_positive_lasso, coefs_positive_lasso, _ = lasso_path(\n",
    "    X, y, eps=eps, positive=True\n",
    ")\n",
    "\n",
    "print(\"Computing regularization path using the LARS...\")\n",
    "alphas_lars, _, coefs_lars = lars_path(X, y, method=\"lasso\")\n",
    "\n",
    "print(\"Computing regularization path using the positive LARS...\")\n",
    "alphas_positive_lars, _, coefs_positive_lars = lars_path(\n",
    "    X, y, method=\"lasso\", positive=True\n",
    ")\n",
    "\n",
    "print(\"Computing regularization path using the elastic net...\")\n",
    "alphas_enet, coefs_enet, _ = enet_path(X, y, eps=eps, l1_ratio=0.8)\n",
    "\n",
    "print(\"Computing regularization path using the positive elastic net...\")\n",
    "alphas_positive_enet, coefs_positive_enet, _ = enet_path(\n",
    "    X, y, eps=eps, l1_ratio=0.8, positive=True\n",
    ")\n",
    "\n",
    "# Display results\n",
    "\n",
    "plt.figure(1)\n",
    "colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
    "for coef_lasso, coef_lars, c in zip(coefs_lasso, coefs_lars, colors):\n",
    "    l1 = plt.semilogx(alphas_lasso, coef_lasso, c=c)\n",
    "    l2 = plt.semilogx(alphas_lars, coef_lars, linestyle=\"--\", c=c)\n",
    "\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"coefficients\")\n",
    "plt.title(\"Lasso and LARS Paths\")\n",
    "plt.legend((l1[-1], l2[-1]), (\"Lasso\", \"LARS\"), loc=\"lower right\")\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.figure(2)\n",
    "colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
    "for coef_l, coef_e, c in zip(coefs_lasso, coefs_enet, colors):\n",
    "    l1 = plt.semilogx(alphas_lasso, coef_l, c=c)\n",
    "    l2 = plt.semilogx(alphas_enet, coef_e, linestyle=\"--\", c=c)\n",
    "\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"coefficients\")\n",
    "plt.title(\"Lasso and Elastic-Net Paths\")\n",
    "plt.legend((l1[-1], l2[-1]), (\"Lasso\", \"Elastic-Net\"), loc=\"lower right\")\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "\n",
    "plt.figure(3)\n",
    "for coef_l, coef_pl, c in zip(coefs_lasso, coefs_positive_lasso, colors):\n",
    "    l1 = plt.semilogy(alphas_lasso, coef_l, c=c)\n",
    "    l2 = plt.semilogy(alphas_positive_lasso, coef_pl, linestyle=\"--\", c=c)\n",
    "\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"coefficients\")\n",
    "plt.title(\"Lasso and positive Lasso\")\n",
    "plt.legend((l1[-1], l2[-1]), (\"Lasso\", \"positive Lasso\"), loc=\"lower right\")\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "\n",
    "plt.figure(4)\n",
    "colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
    "for coef_lars, coef_positive_lars, c in zip(coefs_lars, coefs_positive_lars, colors):\n",
    "    l1 = plt.semilogx(alphas_lars, coef_lars, c=c)\n",
    "    l2 = plt.semilogx(alphas_positive_lars, coef_positive_lars, linestyle=\"--\", c=c)\n",
    "\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"coefficients\")\n",
    "plt.title(\"LARS and Positive LARS\")\n",
    "plt.legend((l1[-1], l2[-1]), (\"LARS\", \"Positive LARS\"), loc=\"lower right\")\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.figure(5)\n",
    "for coef_e, coef_pe, c in zip(coefs_enet, coefs_positive_enet, colors):\n",
    "    l1 = plt.semilogx(alphas_enet, coef_e, c=c)\n",
    "    l2 = plt.semilogx(alphas_positive_enet, coef_pe, linestyle=\"--\", c=c)\n",
    "\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"coefficients\")\n",
    "plt.title(\"Elastic-Net and positive Elastic-Net\")\n",
    "plt.legend((l1[-1], l2[-1]), (\"Elastic-Net\", \"positive Elastic-Net\"), loc=\"lower right\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
