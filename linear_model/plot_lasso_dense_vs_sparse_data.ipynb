{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1973efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "==============================\n",
    "Lasso on dense and sparse data\n",
    "==============================\n",
    "\n",
    "We show that linear_model.Lasso provides the same results for dense and sparse\n",
    "data and that in the case of sparse data the speed is improved.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Authors: The scikit-learn developers\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "from time import time\n",
    "\n",
    "from scipy import linalg, sparse\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# %%\n",
    "# Comparing the two Lasso implementations on Dense data\n",
    "# -----------------------------------------------------\n",
    "#\n",
    "# We create a linear regression problem that is suitable for the Lasso,\n",
    "# that is to say, with more features than samples. We then store the data\n",
    "# matrix in both dense (the usual) and sparse format, and train a Lasso on\n",
    "# each. We compute the runtime of both and check that they learned the\n",
    "# same model by computing the Euclidean norm of the difference between the\n",
    "# coefficients they learned. Because the data is dense, we expect better\n",
    "# runtime with a dense data format.\n",
    "\n",
    "X, y = make_regression(n_samples=200, n_features=5000, random_state=0)\n",
    "# create a copy of X in sparse format\n",
    "X_sp = sparse.coo_matrix(X)\n",
    "\n",
    "alpha = 1\n",
    "sparse_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=1000)\n",
    "dense_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=1000)\n",
    "\n",
    "t0 = time()\n",
    "sparse_lasso.fit(X_sp, y)\n",
    "print(f\"Sparse Lasso done in {(time() - t0):.3f}s\")\n",
    "\n",
    "t0 = time()\n",
    "dense_lasso.fit(X, y)\n",
    "print(f\"Dense Lasso done in {(time() - t0):.3f}s\")\n",
    "\n",
    "# compare the regression coefficients\n",
    "coeff_diff = linalg.norm(sparse_lasso.coef_ - dense_lasso.coef_)\n",
    "print(f\"Distance between coefficients : {coeff_diff:.2e}\")\n",
    "\n",
    "#\n",
    "# %%\n",
    "# Comparing the two Lasso implementations on Sparse data\n",
    "# ------------------------------------------------------\n",
    "#\n",
    "# We make the previous problem sparse by replacing all small values with 0\n",
    "# and run the same comparisons as above. Because the data is now sparse, we\n",
    "# expect the implementation that uses the sparse data format to be faster.\n",
    "\n",
    "# make a copy of the previous data\n",
    "Xs = X.copy()\n",
    "# make Xs sparse by replacing the values lower than 2.5 with 0s\n",
    "Xs[Xs < 2.5] = 0.0\n",
    "# create a copy of Xs in sparse format\n",
    "Xs_sp = sparse.coo_matrix(Xs)\n",
    "Xs_sp = Xs_sp.tocsc()\n",
    "\n",
    "# compute the proportion of non-zero coefficient in the data matrix\n",
    "print(f\"Matrix density : {(Xs_sp.nnz / float(X.size) * 100):.3f}%\")\n",
    "\n",
    "alpha = 0.1\n",
    "sparse_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=10000)\n",
    "dense_lasso = Lasso(alpha=alpha, fit_intercept=False, max_iter=10000)\n",
    "\n",
    "t0 = time()\n",
    "sparse_lasso.fit(Xs_sp, y)\n",
    "print(f\"Sparse Lasso done in {(time() - t0):.3f}s\")\n",
    "\n",
    "t0 = time()\n",
    "dense_lasso.fit(Xs, y)\n",
    "print(f\"Dense Lasso done in  {(time() - t0):.3f}s\")\n",
    "\n",
    "# compare the regression coefficients\n",
    "coeff_diff = linalg.norm(sparse_lasso.coef_ - dense_lasso.coef_)\n",
    "print(f\"Distance between coefficients : {coeff_diff:.2e}\")\n",
    "\n",
    "# %%\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
