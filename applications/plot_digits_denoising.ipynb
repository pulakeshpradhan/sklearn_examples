{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29461e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================\n",
    "Image denoising using kernel PCA\n",
    "================================\n",
    "\n",
    "This example shows how to use :class:`~sklearn.decomposition.KernelPCA` to\n",
    "denoise images. In short, we take advantage of the approximation function\n",
    "learned during `fit` to reconstruct the original image.\n",
    "\n",
    "We will compare the results with an exact reconstruction using\n",
    ":class:`~sklearn.decomposition.PCA`.\n",
    "\n",
    "We will use USPS digits dataset to reproduce presented in Sect. 4 of [1]_.\n",
    "\n",
    ".. rubric:: References\n",
    "\n",
    ".. [1] `Bakır, Gökhan H., Jason Weston, and Bernhard Schölkopf.\n",
    "    \"Learning to find pre-images.\"\n",
    "    Advances in neural information processing systems 16 (2004): 449-456.\n",
    "    <https://papers.nips.cc/paper/2003/file/ac1ad983e08ad3304a97e147f522747e-Paper.pdf>`_\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Authors: The scikit-learn developers\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "# %%\n",
    "# Load the dataset via OpenML\n",
    "# ---------------------------\n",
    "#\n",
    "# The USPS digits datasets is available in OpenML. We use\n",
    "# :func:`~sklearn.datasets.fetch_openml` to get this dataset. In addition, we\n",
    "# normalize the dataset such that all pixel values are in the range (0, 1).\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X, y = fetch_openml(data_id=41082, as_frame=False, return_X_y=True)\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "# %%\n",
    "# The idea will be to learn a PCA basis (with and without a kernel) on\n",
    "# noisy images and then use these models to reconstruct and denoise these\n",
    "# images.\n",
    "#\n",
    "# Thus, we split our dataset into a training and testing set composed of 1,000\n",
    "# samples for the training and 100 samples for testing. These images are\n",
    "# noise-free and we will use them to evaluate the efficiency of the denoising\n",
    "# approaches. In addition, we create a copy of the original dataset and add a\n",
    "# Gaussian noise.\n",
    "#\n",
    "# The idea of this application, is to show that we can denoise corrupted images\n",
    "# by learning a PCA basis on some uncorrupted images. We will use both a PCA\n",
    "# and a kernel-based PCA to solve this problem.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=0, train_size=1_000, test_size=100\n",
    ")\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "noise = rng.normal(scale=0.25, size=X_test.shape)\n",
    "X_test_noisy = X_test + noise\n",
    "\n",
    "noise = rng.normal(scale=0.25, size=X_train.shape)\n",
    "X_train_noisy = X_train + noise\n",
    "\n",
    "# %%\n",
    "# In addition, we will create a helper function to qualitatively assess the\n",
    "# image reconstruction by plotting the test images.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_digits(X, title):\n",
    "    \"\"\"Small helper function to plot 100 digits.\"\"\"\n",
    "    fig, axs = plt.subplots(nrows=10, ncols=10, figsize=(8, 8))\n",
    "    for img, ax in zip(X, axs.ravel()):\n",
    "        ax.imshow(img.reshape((16, 16)), cmap=\"Greys\")\n",
    "        ax.axis(\"off\")\n",
    "    fig.suptitle(title, fontsize=24)\n",
    "\n",
    "\n",
    "# %%\n",
    "# In addition, we will use the mean squared error (MSE) to quantitatively\n",
    "# assess the image reconstruction.\n",
    "#\n",
    "# Let's first have a look to see the difference between noise-free and noisy\n",
    "# images. We will check the test set in this regard.\n",
    "plot_digits(X_test, \"Uncorrupted test images\")\n",
    "plot_digits(\n",
    "    X_test_noisy, f\"Noisy test images\\nMSE: {np.mean((X_test - X_test_noisy) ** 2):.2f}\"\n",
    ")\n",
    "\n",
    "# %%\n",
    "# Learn the `PCA` basis\n",
    "# ---------------------\n",
    "#\n",
    "# We can now learn our PCA basis using both a linear PCA and a kernel PCA that\n",
    "# uses a radial basis function (RBF) kernel.\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "pca = PCA(n_components=32, random_state=42)\n",
    "kernel_pca = KernelPCA(\n",
    "    n_components=400,\n",
    "    kernel=\"rbf\",\n",
    "    gamma=1e-3,\n",
    "    fit_inverse_transform=True,\n",
    "    alpha=5e-3,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "pca.fit(X_train_noisy)\n",
    "_ = kernel_pca.fit(X_train_noisy)\n",
    "\n",
    "# %%\n",
    "# Reconstruct and denoise test images\n",
    "# -----------------------------------\n",
    "#\n",
    "# Now, we can transform and reconstruct the noisy test set. Since we used less\n",
    "# components than the number of original features, we will get an approximation\n",
    "# of the original set. Indeed, by dropping the components explaining variance\n",
    "# in PCA the least, we hope to remove noise. Similar thinking happens in kernel\n",
    "# PCA; however, we expect a better reconstruction because we use a non-linear\n",
    "# kernel to learn the PCA basis and a kernel ridge to learn the mapping\n",
    "# function.\n",
    "X_reconstructed_kernel_pca = kernel_pca.inverse_transform(\n",
    "    kernel_pca.transform(X_test_noisy)\n",
    ")\n",
    "X_reconstructed_pca = pca.inverse_transform(pca.transform(X_test_noisy))\n",
    "\n",
    "# %%\n",
    "plot_digits(X_test, \"Uncorrupted test images\")\n",
    "plot_digits(\n",
    "    X_reconstructed_pca,\n",
    "    f\"PCA reconstruction\\nMSE: {np.mean((X_test - X_reconstructed_pca) ** 2):.2f}\",\n",
    ")\n",
    "plot_digits(\n",
    "    X_reconstructed_kernel_pca,\n",
    "    (\n",
    "        \"Kernel PCA reconstruction\\n\"\n",
    "        f\"MSE: {np.mean((X_test - X_reconstructed_kernel_pca) ** 2):.2f}\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# %%\n",
    "# PCA has a lower MSE than kernel PCA. However, the qualitative analysis might\n",
    "# not favor PCA instead of kernel PCA. We observe that kernel PCA is able to\n",
    "# remove background noise and provide a smoother image.\n",
    "#\n",
    "# However, it should be noted that the results of the denoising with kernel PCA\n",
    "# will depend of the parameters `n_components`, `gamma`, and `alpha`.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
