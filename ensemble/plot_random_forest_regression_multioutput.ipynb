{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc33c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "============================================================\n",
    "Comparing random forests and the multi-output meta estimator\n",
    "============================================================\n",
    "\n",
    "An example to compare multi-output regression with random forest and\n",
    "the :ref:`multioutput.MultiOutputRegressor <multiclass>` meta-estimator.\n",
    "\n",
    "This example illustrates the use of the\n",
    ":ref:`multioutput.MultiOutputRegressor <multiclass>` meta-estimator\n",
    "to perform multi-output regression. A random forest regressor is used,\n",
    "which supports multi-output regression natively, so the results can be\n",
    "compared.\n",
    "\n",
    "The random forest regressor will only ever predict values within the\n",
    "range of observations or closer to zero for each of the targets. As a\n",
    "result the predictions are biased towards the centre of the circle.\n",
    "\n",
    "Using a single underlying feature the model learns both the\n",
    "x and y coordinate as output.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Authors: The scikit-learn developers\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Create a random dataset\n",
    "rng = np.random.RandomState(1)\n",
    "X = np.sort(200 * rng.rand(600, 1) - 100, axis=0)\n",
    "y = np.array([np.pi * np.sin(X).ravel(), np.pi * np.cos(X).ravel()]).T\n",
    "y += 0.5 - rng.rand(*y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=400, test_size=200, random_state=4\n",
    ")\n",
    "\n",
    "max_depth = 30\n",
    "regr_multirf = MultiOutputRegressor(\n",
    "    RandomForestRegressor(n_estimators=100, max_depth=max_depth, random_state=0)\n",
    ")\n",
    "regr_multirf.fit(X_train, y_train)\n",
    "\n",
    "regr_rf = RandomForestRegressor(n_estimators=100, max_depth=max_depth, random_state=2)\n",
    "regr_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on new data\n",
    "y_multirf = regr_multirf.predict(X_test)\n",
    "y_rf = regr_rf.predict(X_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "s = 50\n",
    "a = 0.4\n",
    "plt.scatter(\n",
    "    y_test[:, 0],\n",
    "    y_test[:, 1],\n",
    "    edgecolor=\"k\",\n",
    "    c=\"navy\",\n",
    "    s=s,\n",
    "    marker=\"s\",\n",
    "    alpha=a,\n",
    "    label=\"Data\",\n",
    ")\n",
    "plt.scatter(\n",
    "    y_multirf[:, 0],\n",
    "    y_multirf[:, 1],\n",
    "    edgecolor=\"k\",\n",
    "    c=\"cornflowerblue\",\n",
    "    s=s,\n",
    "    alpha=a,\n",
    "    label=\"Multi RF score=%.2f\" % regr_multirf.score(X_test, y_test),\n",
    ")\n",
    "plt.scatter(\n",
    "    y_rf[:, 0],\n",
    "    y_rf[:, 1],\n",
    "    edgecolor=\"k\",\n",
    "    c=\"c\",\n",
    "    s=s,\n",
    "    marker=\"^\",\n",
    "    alpha=a,\n",
    "    label=\"RF score=%.2f\" % regr_rf.score(X_test, y_test),\n",
    ")\n",
    "plt.xlim([-6, 6])\n",
    "plt.ylim([-6, 6])\n",
    "plt.xlabel(\"target 1\")\n",
    "plt.ylabel(\"target 2\")\n",
    "plt.title(\"Comparing random forests and the multi-output meta estimator\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
