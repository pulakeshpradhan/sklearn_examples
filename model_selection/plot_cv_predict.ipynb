{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f0327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================================\n",
    "Plotting Cross-Validated Predictions\n",
    "====================================\n",
    "\n",
    "This example shows how to use\n",
    ":func:`~sklearn.model_selection.cross_val_predict` together with\n",
    ":class:`~sklearn.metrics.PredictionErrorDisplay` to visualize prediction\n",
    "errors.\n",
    "\"\"\"\n",
    "\n",
    "# Authors: The scikit-learn developers\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "# %%\n",
    "# We will load the diabetes dataset and create an instance of a linear\n",
    "# regression model.\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "lr = LinearRegression()\n",
    "\n",
    "# %%\n",
    "# :func:`~sklearn.model_selection.cross_val_predict` returns an array of the\n",
    "# same size of `y` where each entry is a prediction obtained by cross\n",
    "# validation.\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(lr, X, y, cv=10)\n",
    "\n",
    "# %%\n",
    "# Since `cv=10`, it means that we trained 10 models and each model was\n",
    "# used to predict on one of the 10 folds. We can now use the\n",
    "# :class:`~sklearn.metrics.PredictionErrorDisplay` to visualize the\n",
    "# prediction errors.\n",
    "#\n",
    "# On the left axis, we plot the observed values :math:`y` vs. the predicted\n",
    "# values :math:`\\hat{y}` given by the models. On the right axis, we plot the\n",
    "# residuals (i.e. the difference between the observed values and the predicted\n",
    "# values) vs. the predicted values.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y,\n",
    "    y_pred=y_pred,\n",
    "    kind=\"actual_vs_predicted\",\n",
    "    subsample=100,\n",
    "    ax=axs[0],\n",
    "    random_state=0,\n",
    ")\n",
    "axs[0].set_title(\"Actual vs. Predicted values\")\n",
    "PredictionErrorDisplay.from_predictions(\n",
    "    y,\n",
    "    y_pred=y_pred,\n",
    "    kind=\"residual_vs_predicted\",\n",
    "    subsample=100,\n",
    "    ax=axs[1],\n",
    "    random_state=0,\n",
    ")\n",
    "axs[1].set_title(\"Residuals vs. Predicted Values\")\n",
    "fig.suptitle(\"Plotting cross-validated predictions\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# It is important to note that we used\n",
    "# :func:`~sklearn.model_selection.cross_val_predict` for visualization\n",
    "# purpose only in this example.\n",
    "#\n",
    "# It would be problematic to\n",
    "# quantitatively assess the model performance by computing a single\n",
    "# performance metric from the concatenated predictions returned by\n",
    "# :func:`~sklearn.model_selection.cross_val_predict`\n",
    "# when the different CV folds vary by size and distributions.\n",
    "#\n",
    "# It is recommended to compute per-fold performance metrics using:\n",
    "# :func:`~sklearn.model_selection.cross_val_score` or\n",
    "# :func:`~sklearn.model_selection.cross_validate` instead.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
