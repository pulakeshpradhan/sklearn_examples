{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d449a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=========================================\n",
    "Image denoising using dictionary learning\n",
    "=========================================\n",
    "\n",
    "An example comparing the effect of reconstructing noisy fragments\n",
    "of a raccoon face image using firstly online :ref:`DictionaryLearning` and\n",
    "various transform methods.\n",
    "\n",
    "The dictionary is fitted on the distorted left half of the image, and\n",
    "subsequently used to reconstruct the right half. Note that even better\n",
    "performance could be achieved by fitting to an undistorted (i.e.\n",
    "noiseless) image, but here we start from the assumption that it is not\n",
    "available.\n",
    "\n",
    "A common practice for evaluating the results of image denoising is by looking\n",
    "at the difference between the reconstruction and the original image. If the\n",
    "reconstruction is perfect this will look like Gaussian noise.\n",
    "\n",
    "It can be seen from the plots that the results of :ref:`omp` with two\n",
    "non-zero coefficients is a bit less biased than when keeping only one\n",
    "(the edges look less prominent). It is in addition closer from the ground\n",
    "truth in Frobenius norm.\n",
    "\n",
    "The result of :ref:`least_angle_regression` is much more strongly biased: the\n",
    "difference is reminiscent of the local intensity value of the original image.\n",
    "\n",
    "Thresholding is clearly not useful for denoising, but it is here to show that\n",
    "it can produce a suggestive output with very high speed, and thus be useful\n",
    "for other tasks such as object classification, where performance is not\n",
    "necessarily related to visualisation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Authors: The scikit-learn developers\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "# %%\n",
    "# Generate distorted image\n",
    "# ------------------------\n",
    "import numpy as np\n",
    "\n",
    "try:  # Scipy >= 1.10\n",
    "    from scipy.datasets import face\n",
    "except ImportError:\n",
    "    from scipy.misc import face\n",
    "\n",
    "raccoon_face = face(gray=True)\n",
    "\n",
    "# Convert from uint8 representation with values between 0 and 255 to\n",
    "# a floating point representation with values between 0 and 1.\n",
    "raccoon_face = raccoon_face / 255.0\n",
    "\n",
    "# downsample for higher speed\n",
    "raccoon_face = (\n",
    "    raccoon_face[::4, ::4]\n",
    "    + raccoon_face[1::4, ::4]\n",
    "    + raccoon_face[::4, 1::4]\n",
    "    + raccoon_face[1::4, 1::4]\n",
    ")\n",
    "raccoon_face /= 4.0\n",
    "height, width = raccoon_face.shape\n",
    "\n",
    "# Distort the right half of the image\n",
    "print(\"Distorting image...\")\n",
    "distorted = raccoon_face.copy()\n",
    "distorted[:, width // 2 :] += 0.075 * np.random.randn(height, width // 2)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Display the distorted image\n",
    "# ---------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show_with_diff(image, reference, title):\n",
    "    \"\"\"Helper function to display denoising\"\"\"\n",
    "    plt.figure(figsize=(5, 3.3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Image\")\n",
    "    plt.imshow(image, vmin=0, vmax=1, cmap=plt.cm.gray, interpolation=\"nearest\")\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.subplot(1, 2, 2)\n",
    "    difference = image - reference\n",
    "\n",
    "    plt.title(\"Difference (norm: %.2f)\" % np.sqrt(np.sum(difference**2)))\n",
    "    plt.imshow(\n",
    "        difference, vmin=-0.5, vmax=0.5, cmap=plt.cm.PuOr, interpolation=\"nearest\"\n",
    "    )\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.suptitle(title, size=16)\n",
    "    plt.subplots_adjust(0.02, 0.02, 0.98, 0.79, 0.02, 0.2)\n",
    "\n",
    "\n",
    "show_with_diff(distorted, raccoon_face, \"Distorted image\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# Extract reference patches\n",
    "# ----------------------------\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "# Extract all reference patches from the left half of the image\n",
    "print(\"Extracting reference patches...\")\n",
    "t0 = time()\n",
    "patch_size = (7, 7)\n",
    "data = extract_patches_2d(distorted[:, : width // 2], patch_size)\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "data -= np.mean(data, axis=0)\n",
    "data /= np.std(data, axis=0)\n",
    "print(f\"{data.shape[0]} patches extracted in %.2fs.\" % (time() - t0))\n",
    "\n",
    "\n",
    "# %%\n",
    "# Learn the dictionary from reference patches\n",
    "# -------------------------------------------\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "\n",
    "print(\"Learning the dictionary...\")\n",
    "t0 = time()\n",
    "dico = MiniBatchDictionaryLearning(\n",
    "    # increase to 300 for higher quality results at the cost of slower\n",
    "    # training times.\n",
    "    n_components=50,\n",
    "    batch_size=200,\n",
    "    alpha=1.0,\n",
    "    max_iter=10,\n",
    ")\n",
    "V = dico.fit(data).components_\n",
    "dt = time() - t0\n",
    "print(f\"{dico.n_iter_} iterations / {dico.n_steps_} steps in {dt:.2f}.\")\n",
    "\n",
    "plt.figure(figsize=(4.2, 4))\n",
    "for i, comp in enumerate(V[:100]):\n",
    "    plt.subplot(10, 10, i + 1)\n",
    "    plt.imshow(comp.reshape(patch_size), cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.suptitle(\n",
    "    \"Dictionary learned from face patches\\n\"\n",
    "    + \"Train time %.1fs on %d patches\" % (dt, len(data)),\n",
    "    fontsize=16,\n",
    ")\n",
    "plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Extract noisy patches and reconstruct them using the dictionary\n",
    "# ---------------------------------------------------------------\n",
    "from sklearn.feature_extraction.image import reconstruct_from_patches_2d\n",
    "\n",
    "print(\"Extracting noisy patches... \")\n",
    "t0 = time()\n",
    "data = extract_patches_2d(distorted[:, width // 2 :], patch_size)\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "intercept = np.mean(data, axis=0)\n",
    "data -= intercept\n",
    "print(\"done in %.2fs.\" % (time() - t0))\n",
    "\n",
    "transform_algorithms = [\n",
    "    (\"Orthogonal Matching Pursuit\\n1 atom\", \"omp\", {\"transform_n_nonzero_coefs\": 1}),\n",
    "    (\"Orthogonal Matching Pursuit\\n2 atoms\", \"omp\", {\"transform_n_nonzero_coefs\": 2}),\n",
    "    (\"Least-angle regression\\n4 atoms\", \"lars\", {\"transform_n_nonzero_coefs\": 4}),\n",
    "    (\"Thresholding\\n alpha=0.1\", \"threshold\", {\"transform_alpha\": 0.1}),\n",
    "]\n",
    "\n",
    "reconstructions = {}\n",
    "for title, transform_algorithm, kwargs in transform_algorithms:\n",
    "    print(title + \"...\")\n",
    "    reconstructions[title] = raccoon_face.copy()\n",
    "    t0 = time()\n",
    "    dico.set_params(transform_algorithm=transform_algorithm, **kwargs)\n",
    "    code = dico.transform(data)\n",
    "    patches = np.dot(code, V)\n",
    "\n",
    "    patches += intercept\n",
    "    patches = patches.reshape(len(data), *patch_size)\n",
    "    if transform_algorithm == \"threshold\":\n",
    "        patches -= patches.min()\n",
    "        patches /= patches.max()\n",
    "    reconstructions[title][:, width // 2 :] = reconstruct_from_patches_2d(\n",
    "        patches, (height, width // 2)\n",
    "    )\n",
    "    dt = time() - t0\n",
    "    print(\"done in %.2fs.\" % dt)\n",
    "    show_with_diff(reconstructions[title], raccoon_face, title + \" (time: %.1fs)\" % dt)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
